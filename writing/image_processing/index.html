<!doctype html><style>html{height:100vh}body{min-height:100vh;display:grid;grid-template-rows:1fr auto}.footer{grid-row-start:2;grid-row-end:3}</style><html lang=en-gb><head><meta charset=utf-8><title>Sam Robbins</title><link rel=canonical href=https://samrobbins.uk/writing/image_processing/><meta name=viewport content="width=device-width,initial-scale=1"><meta name=monetization content="$ilp.uphold.com/reGxiLfZfUmn"><meta name=description property="og:description" content="My report for the Image Processing module at University"><meta name=image property="og:image" content="/"><meta name=author content="Sam Robbins"><meta name=generator content="Hugo 0.75.1"><link rel=stylesheet href=/css/syntax.min.css integrity media=screen><script src=https://cdn.jsdelivr.net/npm/mailgo@0.9.14/dist/mailgo.min.js defer></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link href=/css/tailwind.min.css rel=stylesheet><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "8348650db5154c01999667d263b7e6e1"}'></script></head><body class=writing><div class=wrapper><nav class="fixed h-16 p-4 bg-white border-b border-gray-200 w-full z-20"><div class="flex divide-x-4 divide-transparent pr-6 text-lg items-center text-gray-700"><a href=/ class=font-normal>Home</a>
<a href=/about/ title=About>About</a>
<a href=/blog/ title=Blog>Blog</a>
<a href=/portfolio/ title=Portfolio>Portfolio</a>
<a class="text-gray-800 font-semibold" href=/writing/ title=Writing>Writing</a></div></nav><section class="pt-20 px-4"><div class="container mx-auto"><h1 class="sm:text-4xl text-2xl text-center font-semibold">A report on Non-Local Means Denoising</h1><div class="py-4 text-gray-600"><p class=text-center><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-4 w-4 inline-block stroke-current text-gray-600"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>Jan 20, 2020</p><p class=text-center><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-4 w-4 inline-block stroke-current text-gray-600"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>7 minutes</p></div><hr class=my-4></div></div></section><div class="container prose mx-auto w-screen px-4 pb-6"><h1 id=a-description-of-the-non-local-means-denoising-algorithm>A description of the non-local means denoising algorithm</h1><p><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> Non local means denoising uses samples from all
around the image, instead of conventional denoising which will just look
at the area around the given pixel to increase the accuracy of the
colour. The reason it does this is due to the fact that patterns and
shapes will be repeated in images, meaning that there will likely be an
area somewhere else in the image that looks very similar to the patch
around the pixel looking to be corrected. By finding these areas and
taking averages of the pixels in similar areas, the noise will reduce as
the random noise will converge around the true value.</p><p>So the method by which non-local means runs is to look at many patches
throughout the image, and compare the similarities of those patches with
the patch around the pixel looking to be denoised. This comparison then
allows for assigning a weight to each patch looked at, which are then
used (along with the colour of the pixel in the centre of the patch) in
the calculation of the colour of the pixel to be denoised.</p><h1 id=various-implementations-of-the-algorithm-and-their-efficiency>Various implementations of the algorithm and their efficiency</h1><h2 id=pixelwise>Pixelwise</h2><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781993/drawing_tgntf0.png alt="Visualisation of pixelwise denoising"><figcaption>Visualisation of pixelwise denoising</figcaption></figure></p><p><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>Taking an image u and a pixel in it you want to
denoise, p, you first need to decide a patch size, given by r, as the
dimensions of the patch (blue) are $(2r+1)\times(2r+1)$. You then look
at all the other pixels, $q\in Q$, but as it is intensive to do the
calculations, specifying a research zone (red) allows you to make the
processing faster as fewer comparisons have to be done. When looking at
the other pixels, calculate their patch of the same size as the patch of
p, then compare each pixel in the patch of q with the corresponding
pixel in the patch of p. This similarity is then used to compute the
similarity between the patch around p and the patch around q, and a
weighting is given to q to describe this. These weightings are then
averaged with the colours of the pixels to provide a more accurate
representation of the pixel.</p><h2 id=patchwise>Patchwise</h2><p><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> The main way in which patchwise differs from
pixelwise is in the formulation of the weighting, as you can see below</p><p>$$C(p)=\sum_{q \in B(p, r)} w(p, q)$$</p><p>$$C=\sum_{Q=Q(q, f) \in B(p, r)} w(B, Q)$$</p><p>By calculating weights for pixels instead of patches we can make one
calculation per patch, therefore not needing to do $(2f+1)^2$
calculations per pixel, providing a large increase in performance. The
overall quality of the two methods are the same, and so the patchwise
method is preferred as it has no drawbacks for an improvement in speed.</p><h1 id=the-strengths-and-limitations-of-non-local-means-compared-to-other-denoising-algorithms>The strengths and limitations of non-local means compared to other denoising algorithms</h1><h2 id=method-noise>Method noise</h2><p><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup><strong>Definition (method noise)</strong>. Let u be a (not
necessarily noisy) image and $D_h$ a denoising operator depending on h.
Then we define the method noise of u as the image difference</p><p>$$
n(D_h,u)=u-D_h(u)
$$</p><p>This method noise should be as similar to white
noise as possible. The image below is sourced from <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></p><p><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781986/method_noise_lhu9zs.png alt=image></p><p>From left to right and from top to bottom: original image,Gaussian
convolution, mean curvature motion, total variation, Tadmor–Nezzar–Vese
iterated total variation, Osher et al. total variation, neighborhood
filter, soft TIWT, hard TIWT, DCT empirical Wiener filter, and the
NL-means algorithm.</p><p>You can see that the NL means algorithm is closest to white noise, as it
is very difficult to make out the original image from the method noise,
and so is the best in this area</p><h2 id=mean-square-error>Mean square error</h2><p><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>The mean square error measures the average squared
difference between the estimated values and what is estimated. In images
this acts as a measure of how far from the true image the denoised image
is. These results are taken from <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></p><p><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781984/mean_eewg2j.png alt=image></p><p>Here it can be seen that the NL-means algorithm gives images that are
closest to the true image, and so performs best for image denoising
under this measurement.</p><h1 id=the-influence-of-the-algorithmic-parameters-on-the-output>The influence of the algorithmic parameters on the output</h1><p>In the following images I am changing the values of h, the template
window size and the search window size, from a standard set at h=5,
template window size=7 and search window size =21. I will adjust each
one in turn to show the differences yielded by changing them.</p><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781994/h2_zk03fm.png alt="h=2"><figcaption>h=2</figcaption></figure></p><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781996/h10_vmlxaf.png alt="h=10"><figcaption>h=10</figcaption></figure></p><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781996/h10_vmlxaf.png alt="template=2"><figcaption>template width = 2</figcaption></figure></p><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781991/template15_s8c518.png alt="template=10"><figcaption>template width = 10</figcaption></figure></p><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781993/search10_bzpgw4.png alt="search=10"><figcaption>search window size = 10</figcaption></figure></p><p><figure><img src=https://res.cloudinary.com/samrobbins/image/upload/v1600781995/search30_uwv1vx.png alt="search=30"><figcaption>search window size = 30</figcaption></figure></p><p>By adjusting the value of h you get a large change in the amount of
smoothing, although a large amount of noise is still present. Increasing
the value of h does increase the PSNR from 28.60 to 29.66</p><p>The effects from adjusting the template width are much more subtle than
that of adjusting h, it can be noticed in the wires overhead that a
larger template width has reduced the detail. An increase in the
template width yields a small reduction in the PSNR from 28.68 to
28.51.</p><p>The effects for the value of the search window are also very subtle, and
again can only be noticed fully in the overhead wires. An increase in
the search window yields a marginal increase in the PSNR from 28.51 to
28.52.</p><h1 id=modifications-and-extensions-of-the-algorithm-that-have-been-proposed-in-the-literature>Modifications and extensions of the algorithm that have been proposed in the literature</h1><h2 id=testing-stationarity>Testing stationarity</h2><p><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> One proposed modification is one to test
stationarity. The original algorithm works under the conditional
expectation process:</p><p><strong>Theorem</strong> - Conditional Expectation Theorem</p><p>Let $Z_j={X_j,Y_j}$ for $j=1,2,&mldr;$ be a strictly stationary and mixing process. For $i\in I$, let $X$ and $Y$ be distributed as $X_i$ and $Y_i$. Let J be a compact subset $J\subset \mathbb{R}^p$ such that</p><p>$$
\inf{f_X(x);x\in J}>0
$$</p><p>However this is not true everywhere, as each image may contain
exceptional, non-repeated structures, these would be blurred out by the
algorithm, so the algorithm should have a detection phase and special
treatment of nonstationary points. In order to use this strategy a good
estimate of the mean and variance at every pixel is needed, fortunately
the non-local means algorithm converges to the conditional mean, and the
variance can just be calculated using $EX^2-(EX)^2$</p><h2 id=multiscale-version>Multiscale version</h2><p>Another improvement to make is one to speed up the algorithm, this is
proposed using a multiscale algorithm.</p><ol><li><p>Zoom out the image $u_0$ by a factor of 2. This gives the new image
$u_1$</p></li><li><p>Apply the NL means algorithm to $u_1$, so that with each pixel of
$u_1$, a list of windows centered in $(i_1,j_1)&mldr;(i_k,j_k)$ is
associated</p></li><li><p>For each pixel of $u_0$, $(2i+r,2j+s)$ with $r,s\in {0,1}$, we
apply the NL means algorithm. However instead of comparing with all
the windows in the search zone, we just compare with the 9
neighbouring windows of each pixel</p></li><li><p>This procedure can be applied in a pyramid fashion</p></li></ol><h1 id=applications-of-the-original-algorithm-and-its-extensions>Applications of the original algorithm and its extensions</h1><h2 id=medical-imaging>Medical Imaging</h2><p><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> It has been proposed that Non-Local means can
be used in X-Ray imaging, allowing for a reduction of noise in the
scans, making them easier to interpret. In CT scans a higher dose can be
given to give a clearer image, but with that is more dangerous, however
by applying the NL means algorithm a lower dose can be given for the
same clarity. It benefits from the improvement stated above to test
stationarity as the the noise and streak artifacts are non stationary.
The original algorithm was also not good at removing the streak
artifacts in low-flux CT images resulting from photon starvation.
However by applying one-dimensional nonlinear diffusion in the
stationary wavelet domain before applying the non-local means algorithm
these could be reduced.</p><h2 id=video-denoising>Video Denoising</h2><p><sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup> NLM can also be applied in video denoising, it has
an adaptation as the denoising can be improved by using the data from
sequential frames. In the implementation proposed in the paper, the
current input frame and prior output frame are used to form the current
output frame. In the paper the measurements they make fail to show that
this algorithm is an improvement from current algorithms, however the
algorithm does have much better subjective visual performance.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Buades, A., Coll, B., and Morel, J.M. 2005. A Non-Local Algorithm for Image Denoising. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) (pp. 60–65). IEEE. <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Buades, A., Coll, B., and Morel, J.M. 2011. Non-Local Means Denoising. Image Processing On Line, 1. <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Buades, A., Coll, B., and Morel, J. 2005. A Review of Image Denoising Algorithms, with a New One. Multiscale Modeling & Simulation, 4(2), p.490–530. <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Machine learning: an introduction to mean squared error and regression lines. URL <a href=https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/>https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/</a>. <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>Zhang, H., Zeng, D., Zhang, H., Wang, J., Liang, Z., and Ma, J. 2017. Applications of nonlocal means algorithm in low-dose X-ray CT image processing and reconstruction: A review. Medical Physics, 44(3), p.1168–1185. <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>Ali, R., and Hardie, R. 2017. Recursive non-local means filter for video denoising. EURASIP Journal on Image and Video Processing, 2017(1), p.29. <a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous></div></body></html>